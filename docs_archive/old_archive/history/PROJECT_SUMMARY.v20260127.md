# Workflow Test Bench (WTB) - Project Overview

## 1. System Introduction

**Workflow Test Bench (WTB)** is a specialized testing and orchestration framework designed for agentic workflows (specifically **LangGraph** agents). It addresses the unique challenges of testing non-deterministic, long-running, and side-effect-heavy AI agents by providing enterprise-grade capabilities for state management, debugging, and evaluation.

Unlike standard unit testing frameworks, WTB treats "Time" and "State" as first-class citizens, enabling features like time-travel debugging, parallel branching for A/B testing, and comprehensive artifact tracking.

## 2. Core Value Proposition

* **Reliability**: Ensure agents behave correctly by testing across diverse scenarios and ensuring deterministic recovery from failures.
* **Debuggability**: "Time Travel" capabilities allow developers to step back, inspect state, modify variables, and replay execution from any point.
* **Optimization**: Systematically compare different prompts, models, or logic (A/B testing) using parallel execution branches to find the optimal configuration.

## 3. Key Features

### 3.1 Time Travel & Persistence

* **Checkpointing**: Automatically captures the state of the workflow at every node execution.
* **Rollback**: Instantly revert the entire system (workflow state **AND** file system artifacts) to any previous checkpoint.
* **State Inspection**: Query the exact variable state at any point in the execution history.

### 3.2 Advanced Experimentation

* **Branching**: Create isolated execution branches from any checkpoint to test alternative paths (e.g., trying a different prompt from step 5 of a failed run).
* **Batch Testing**: Run hundreds of test cases in parallel using **Ray** to evaluate performance across varied inputs.
* **Node Hot-Swapping**: Dynamically replace a specific node (e.g., "Generate") with a different implementation (e.g., "GenerateV2") during testing.

### 3.3 Human-in-the-Loop

* **Pause & Resume**: Set breakpoints to pause execution, inspect intermediate results, and resume.
* **State Modification**: Manually patch the workflow state (e.g., fix a hallucinated SQL query) while paused, then resume execution to verify the fix.

### 3.4 File System Versioning

* **FileTracker Integration**: Tracks changes to files generated by agents. When rolling back the workflow state, WTB automatically restores the file system to the matching state, ensuring data consistency.

## 4. System Architecture Components

The system is composed of three primary collaborating systems:

### 4.1 Workflow Test Bench (WTB) - *The Orchestrator*

* **Role**: The "Brain" of the system.
* **Responsibilities**:
  * Parses and executes LangGraph workflows.
  * Manages the execution lifecycle (Start, Stop, Pause, Resume).
  * Orchestrates batch tests and evaluations.
* **Key Component**: `TestOrchestrator`, `ExecutionController`.

### 4.2 Langgraph/AgentGit - *The State Engine*

* **Role**: The "Memory" of the system.
* **Responsibilities**:
  * Persists execution state snapshots (Checkpoints).
  * Manages the "Branching Tree" of execution history.
  * Provides the abstraction for different persistence backends (InMemory, SQLite, PostgreSQL).
* **Key Component**: `AgentGitStateAdapter`.

### 4.3 FileTracker - *The Artifact Engine*

* **Role**: The "Archivist" of the system.
* **Responsibilities**:
  * Uses Content-Addressed Storage (CAS) to deduplicate and store file versions.
  * Links file operations to specific workflow checkpoints.
  * Restores physical files during rollback operations.

### 4.4 Ray Integration - *The Scale Engine*

* **Role**: The "Muscle" for batch processing.
* **Responsibilities**:
  * Distributes batch test execution across multiple workers/nodes.
  * Manages resource isolation (CPUs/Memory) per test variant.

## 5. Directory Structure & Key Resources

* **Documentation**:

  * `docs/Project_Init/WORKFLOW_TEST_BENCH_SUMMARY.md`: Detailed architectural summary and data flows.
  * `docs/Project_Init/WORKFLOW_TEST_BENCH_ARCHITECTURE.md`: Deep dive into technical architecture and critical decisions.
  * `docs/Ray/`: Documentation for distributed batch testing.
* **Examples (`examples/wtb_presentation/`)**:

  * **RAG Pipeline**: Full demo of a Retrieval-Augmented Generation workflow with A/B testing of retrievers.
  * **SQL Agent**: Demo of a tool-using agent with database interaction and rollback capabilities.
  * **Scripts**:
    * `02_rollback_demo.py`: Hands-on rollback demonstration.
    * `03_branch_demo.py`: A/B testing with branches.
    * `04_pause_resume_demo.py`: Human-in-the-loop interaction.

## 6. Integration Guide

### 6.1 Basic Workflow Setup

Users wrap their LangGraph applications in a `WorkflowProject` configuration, specifying:

1. **Graph Definition**: The LangGraph compiled graph.
2. **Configuration**: Environment and resource requirements.

### 6.2 Running Tests

Tests can be run via:

* **SDK**: Python API for granular control (`WTBTestBench`).
* **CLI**: Command-line interface for batch execution.
* **API**: REST/gRPC endpoints for UI integration.

## 7. Observability

* **Audit Trail**: All actions (tool calls, state changes, errors) are recorded in an append-only audit log.
* **Metrics**: Prometheus-compatible metrics for execution duration, success rates, and token usage.
* **Real-time Feedback**: WebSocket/gRPC streams for live execution monitoring in the IDE.
